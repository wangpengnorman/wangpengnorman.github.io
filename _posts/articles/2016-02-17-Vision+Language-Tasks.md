---
layout: article
title: "Vision+Language Tasks"
categories: articles
excerpt: "Vision and Language Tasks like image captioning, visual question answering require the understanding of both vision and language information. We are particularly interested in bridging vision, language and knowledge. Several papers were published in TPAMI and CVPR. "
author: billy_rick
tags: [sample, readability, test]
ads: false
image:
  teaser: research_vqa.jpg
---

We are particularly interested in bridging vision, language and knowledge. 

<u>Related work:</u>

&radic; &nbsp; &nbsp; P. Wang*, Q. Wu*, C. Shen, A. Dick, A. van den Hengel. **FVQA: Fact-based Visual Question Answering**. In: TPAMI, 2018.

&radic; &nbsp; &nbsp; Q. Wu, C. Shen, P. Wang, A. Dick, A. van den Hengel. **Image Captioning and Visual Question Answering based on Attributes and External Knowledge**. In: TPAMI, 2017.

&radic; &nbsp; &nbsp; Q. Wu, P. Wang, C. Shen, I. Reid, A. van den Hengel. **Are You Talking to Me? Reasoned Visual Dialog Generation through Adversarial Learning**. In: CVPR, 2018.

&radic; &nbsp; &nbsp; P. Wang*, Q. Wu*, C. Shen, A. van den Hengel. **The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions**. In: CVPR, 2017.

&radic; &nbsp; &nbsp; P. Wang*, Q. Wu*, C. Shen, A. van den Hengel, A. Dick. **Explicit Knowledge-based Reasoning for Visual Question Answering**. In: IJCAI, 2017.

&radic; &nbsp; &nbsp; Q. Wu, P. Wang, C. Shen, A. Dick, A. van den Hengel. **Ask Me Anything: Free-form Visual Question Answering based on Knowledge from External Sources**. In: CVPR, 2016.
